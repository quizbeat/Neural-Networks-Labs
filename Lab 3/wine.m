%% Классификация вина  (пример из документации Matlab Neural Network Toolbox)
% Задача: определить, на какой винодельне было произведено вино, по его химическим характеристикам.
% Есть три различные винодельни - т.е. три класса.
% Вектора признаков состоят из тринадцати признаков:
%      1. содержание алкоголя
%      2. содержание яблочной кислоты
%      3. содержание золы
%      4. щелочность золы  
%      5. содержание магния
%      6. общее содержание фенолов
%      7. содержание флавоноидных фенолов
%      8. содержание нефлавоноидных фенолов
%      9. содержание проантоцианинов
%     10. интенсивность цвета
%     11. цветовой тон
%     12. OD280/OD315 (отношение спектральной поглощательной способности при длинах волн 280 и 315 нм) разбавленных вин
%     13. содержание пролина

[x,t] = wine_dataset;
n = size(x, 2);%количество пар вход/выход

%%
%Создаем двухслойную сеть с 10 нейронами в скрытом слое 
%и методом обучения Resilient BackPropagation (Эластичное распространение)
net = patternnet(10, 'trainrp');
view(net)
%patternnet изначально заточена под классификацию, и передаточная функция
%в выходном слое - гиперболический тангенс.
%То же самое можно сделать и с помощью 
net = feedforwardnet(10, 'trainrp');%скрытые слое нелинейные, выходной - линейный (удобно в задаче аппркосимации, поскольку там выходы не ограничены [0,1], а принимают значения в диапазоне (-inf, +inf))
net.layers{2}.transferFcn = 'tansig';%теперь в выходном слое - гиперболический тангенс.
view(net)

net.trainFcn = 'traingd';%Так можно менять метод обучения - например, на градиентный спуск
net.trainParam.lr = 0.01;%Настраиваем скорость обучения (у разных методов обучения разные настраиваемые параметры)

net.trainFcn = 'trainscg';%метод Моллера

net.performFcn = 'mse';%критерий оптимизации - среднеквадратичное отклонение
net.trainParam.epochs = 10000;%максимальное количество итераций
net.trainParam.goal = 1.0e-8;%целевая точность
net.trainParam.min_grad = 1.0e-7;%минимальный градиент
net.trainParam.max_fail = 100;%максимальное количество ошибок валидации

net = configure(net, x, t);%настраиваем размерности входов и выходов под обучающее множество
view(net)
%%
%Разделение множества на обучающее, контрольное и тестовое вручную
%Например, разделим индексы поровну на три группы, в порядке чередования
%То есть, [train val test train val test ...]
allInd = 1 : n;
trainInd = allInd(mod(allInd, 3) == 0);%Часть индексов, которые делятся на 3 без остатка
valInd = allInd(mod(allInd, 3) == 1);%Часть индексов, которые при делении на 3 дают остаток 1
testInd = allInd(mod(allInd, 3) == 2);%Часть индексов, которые при делении на 3 дают остаток 2
net.divideFcn = 'divideind';
net.divideParam.trainInd = trainInd;
net.divideParam.valInd = valInd;
net.divideParam.testInd = testInd;

%Другой способ - делить индексы блоками
net.divideFcn = 'divideblock';
net.divideParam.trainRatio = 0.7;%первые 70% пар вход/выход
net.divideParam.valRatio = 0.2;%следующие за ними 20% пар вход/выход
net.divideParam.testRatio = 0.1;%следующие за ними 10% пар вход/выход

%Третий способ - случайное распределение
net.divideFcn = 'dividerand';
net.divideParam.trainRatio = 0.7;% 70% пар вход/выход
net.divideParam.valRatio = 0.2;% 20% пар вход/выход
net.divideParam.testRatio = 0.1;% 10% пар вход/выход

[net, tr] = train(net, x, t);%возвращает обученную net и информацию о процессе обучения tr (training record)
plotperform(tr)%тот же график, что при нажатии на кнопку Performance в окне обучения

% The network outputs will be in the range 0 to 1, so we can use *vec2ind*
% function to get the class indices as the position of the highest element
% in each output vector.
%посмотрим погрешность на тестовом множестве
testX = x(:, tr.testInd);%tr.testInd - индексы тестового множества (только так можно их узнать, если они выбирались случайно)
testT = t(:, tr.testInd);
testY = net(testX);%выходы сети представляют собой вектора из трех чисел (по числу выходов), с значениями в диапазоне от 0 до 1
error = mse(testT - testY);%среднеквадратичное отклонение
testIndices = (testY);%vec2ind преобразует эти вектора в индексы классов - например, [1 0 0] в 1, [0 1 0] в 2, [0 0 1] в 3

%Пространство признаков имеет размерность 13 - тут график не построишь.
%Возьмем срез по трем параметрам - например, по 7 и 8.
%Посмотрим диапазон их значений:
minx = min(x(7,:));
maxx = max(x(7,:));
miny = min(x(8,:));
maxy = max(x(8,:));
dx = (maxx - minx) / 100;
dy = (maxy - miny) / 100;
[xs, ys] = meshgrid(minx : dx : maxx, maxy : -dy : miny);
totalsize = size(xs, 1) * size(xs, 2);%размер сетки
ps = zeros(13, totalsize);
ps(7, :) = xs(:);%линеаризуем xs
ps(8, :) = ys(:);
%для остальных параметров возьмем их средние значения
for i = [1:6 9:13]
    ps(i, :) = ones(1, totalsize) * mean(x(i, :));
end
out = net(ps);%выход сети
out = max(0, min(1, out));%ограничим диапазон [0,1]
out = round(out * 10) * 0.1;%округляем до десятых
ctable = unique(out', 'rows');%находим уникальные вектора, они составляют таблицу цветов
cmap = zeros(n, n);%индексы векторов выходов в таблице цветов запишем в матрицу
for i = 1 : size(ctable, 1)
    cmap(ismember(out', ctable(i, :), 'rows')) = i; 
end
image([minx, maxx], [miny, maxy], cmap); %отображаем матрицу
colormap(ctable);%применяем таблицу цветов
%График не настолько показательный, как эллипсы, но какой есть)

%Построим другой график - все точки исходного множества, по признакам 6, 7
%и 8, цвет соответствует классу
scatter3(x(6, :), x(7, :), x(8, :), 10, vec2ind(net(x))', 'filled')